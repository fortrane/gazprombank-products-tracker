from bs4 import BeautifulSoup
import asyncio
import requests
from datetime import datetime
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from db import DBClient
from classifier import classify_review
from bert_summary import TopicSentimentSummarizer
import os

BASE_URL = "https://www.banki.ru/services/responses/list/ajax/"
BANK = "gazprombank"
async def fetch_data(page: int):
    """–ó–∞–ø—Ä–æ—Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Ç–∑—ã–≤–æ–≤"""
    params = {
        "page": page,
        "is_countable": "on",
        "bank": BANK
    }
    response = requests.get(BASE_URL, params=params)

    if response.status_code == 200:
        print(response.json())
        return response.json()
    else:
        print(f"[{datetime.now()}] ‚ùå Error fetching page {page}: {response.status_code}")
        return None

async def process_review(review: dict, db: DBClient):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ + –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è"""
    date_str = review.get("dateCreate")
    if date_str:
        try:
            review_date = datetime.strptime(date_str, "%Y-%m-%d %H:%M:%S")
        except ValueError:
            review_date = None
    else:
        review_date = None
    soup = BeautifulSoup(review.get("text", ""), "html.parser")
    text = soup.get_text()
    review_data = {
        "product": BANK,
        "bank": BANK,
        "text": text,
        "date": datetime.fromtimestamp(review.get("date", 0)).date(),
        "dateCreate":review_date,
        "id":review.get("id", "")
    }
    review_id = await db.upsert_review(review_data)

    classification = await classify_review(review_data["text"])
    print("Classific",classification)
    aspects= TopicSentimentSummarizer().summarize_single_review(classification)
    print(aspects)
    await db.mark_review_classified(review_id, classification,aspects)

async def fetch_new_reviews_job():
    """–ó–∞–¥–∞—á–∞ –¥–ª—è –ø–æ–¥–≥—Ä—É–∑–∫–∏ –Ω–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–æ–≤"""
    print(f"[{datetime.now()}] üöÄ Fetching new reviews...")

    db = DBClient.get_instance()
    # –£–±–∏—Ä–∞–µ–º db.init() –∏ db.close(), —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ

    for page in range(1,2):
        data = await fetch_data(page)

        if data:
            for r in data["data"]:
                try:
                    await process_review(r, db)
                except Exception as e:
                    print(f"Error processing review: {e}")
    print(f"[{datetime.now()}] ‚úÖ Reviews updated.")


async def alerts_job():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤"""
    from alerts import check_alerts
    print(f"[{datetime.now()}] üîî Running alerts check...")
    db = DBClient.get_instance()
    await check_alerts(db)

async def start_scheduler():
    scheduler = AsyncIOScheduler()

    # –∫–∞–∂–¥—ã–µ 10 –º–∏–Ω—É—Ç ‚Äî –Ω–æ–≤—ã–µ –æ—Ç–∑—ã–≤—ã
    scheduler.add_job(lambda: asyncio.create_task(fetch_new_reviews_job()), 'interval', minutes=10)
    # –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç ‚Äî –∞–ª–µ—Ä—Ç—ã
    scheduler.add_job(lambda: asyncio.create_task(alerts_job()), 'interval', minutes=5)

    scheduler.start()
    print("‚úÖ Scheduler started")
    #await fetch_new_reviews_job()


